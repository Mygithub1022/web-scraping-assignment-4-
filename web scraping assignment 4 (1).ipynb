{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://www.guru99.com/exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html')\n",
    "\n",
    "def heading():\n",
    "  head = soup.find_all('h2')\n",
    "  print(head[1].text)\n",
    "\n",
    "def contentlist():\n",
    "  #find the section where data lies\n",
    "  col = soup.find('table',{'class':'table table-striped'})\n",
    "  insidecol = col.find_all('tr')\n",
    "\n",
    "  for i in range(len(insidecol)):\n",
    "  \n",
    "    print(insidecol[i].text.replace(' ','  -->  ',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Exceptions in Selenium Web driver\n",
      "\n",
      "\n",
      "Exception  -->  name Description  \n",
      "ElementNotVisibleException  -->  This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden. \n",
      "ElementNotSelectableException  -->  This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact. \n",
      "NoSuchElementException  -->  This Exception occurs if an element could not be found. \n",
      "NoSuchFrameException  -->  This Exception occurs if the frame target to be switched to does not exist. \n",
      "NoAlertPresentException  -->  This Exception occurs when you switch to no presented alert. \n",
      "NoSuchWindowException  -->  This Exception occurs if the window target to be switch does not exist. \n",
      "StaleElementReferenceException  -->  This Selenium exception occurs happens when the web element is detached from the current DOM. \n",
      "SessionNotFoundException  -->  The WebDriver is acting after you quit the browser. \n",
      "TimeoutException  -->  Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time. \n",
      "WebDriverException  -->  This Exception takes place when the WebDriver is acting right after you close the browser. \n",
      "ConnectionClosedException  -->  This type of Exception takes place when there is a disconnection in the driver. \n",
      "ElementClickInterceptedException  -->  The command may not be completed as the element receiving the events is concealing the element which was requested clicked. \n",
      "ElementNotInteractableException  -->  This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element. \n",
      "ErrorInResponseException  -->  This happens while interacting with the Firefox extension or the remote driver server. \n",
      "ErrorHandler.UnknownServerException  -->  Exception is used as a placeholder in case if the server returns an error without a stack trace. \n",
      "ImeActivationFailedException  -->  This expectation will occur when IME engine activation has failed. \n",
      "ImeNotAvailableException  -->  It takes place when IME support is unavailable. \n",
      "InsecureCertificateException  -->  Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate. \n",
      "InvalidArgumentException  -->  It occurs when an argument does not belong to the expected type. \n",
      "InvalidCookieDomainException  -->  This happens when you try to add a cookie under a different domain instead of current URL. \n",
      "InvalidCoordinatesException  -->  This type of Exception matches an interacting operation that is not valid. \n",
      "InvalidElementStateExceptio  -->  It occurs when command can't be finished when the element is invalid. \n",
      "InvalidSessionIdException  -->  This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either. \n",
      "InvalidSwitchToTargetException  -->  This occurs when the frame or window target to be switched does not exist. \n",
      "JavascriptException  -->  This issue occurs while executing JavaScript given by the user. \n",
      "JsonException  -->  It occurs when you afford to get the session when the session is not created. \n",
      "NoSuchAttributeException  -->  This kind of Exception occurs when the attribute of an element could not be found. \n",
      "MoveTargetOutOfBoundsException  -->  It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document. \n",
      "NoSuchContextException  -->  ContextAware does mobile device testing. \n",
      "NoSuchCookieException  -->  This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document. \n",
      "NotFoundException  -->  This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist. \n",
      "RemoteDriverServerException  -->  This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper. \n",
      "ScreenshotException  -->  It is not possible to capture a screen. \n",
      "SessionNotCreatedException  -->  It happens when a new session could not be successfully created. \n",
      "UnableToSetCookieException  -->  This occurs if a driver is unable to set a cookie. \n",
      "UnexpectedTagNameException  -->  Happens if a support class did not get a web element as expected. \n",
      "UnhandledAlertException  -->  This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation. \n",
      "UnexpectedAlertPresentException  -->  It occurs when there is the appearance of an unexpected alert. \n",
      "UnknownMethodException  -->  This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL. \n",
      "UnreachableBrowserException  -->  This Exception occurs only when the browser is not able to be opened or crashed because of some reason. \n",
      "UnsupportedCommandException  -->  This occurs when remote WebDriver does n't send valid commands as expected. \n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "  if dump.status_code == 200:\n",
    "    heading()\n",
    "    print('\\n')\n",
    "    contentlist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'http://statisticstimes.com/economy/india/indian-states-gdp.php'\n",
    "\n",
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank,   State,   GSDP (Cr INR at Current prices) 19-20 ,   GSDP (Cr INR at Current prices) 18-19,  Share,  GDP ($billion)\n",
      "1,   Maharashtra,   -,   2,632,792,   13.94%,   399.921\n",
      "2,   Tamil Nadu,   1,845,853,   1,630,208,   8.63%,   247.629\n",
      "3,   Uttar Pradesh,   1,687,818,   1,584,764,   8.39%,   240.726\n",
      "4,   Gujarat,   -,   1,502,899,   7.96%,   228.290\n",
      "5,   Karnataka,   1,631,977,   1,493,127,   7.91%,   226.806\n",
      "6,   West Bengal,   1,253,832,   1,089,898,   5.77%,   165.556\n",
      "7,   Rajasthan,   1,020,989,   942,586,   4.99%,   143.179\n",
      "8,   Andhra Pradesh,   972,782,   862,957,   4.57%,   131.083\n",
      "9,   elangana,   969,604,   861,031,   4.56%,   130.791\n",
      "10,   Madhya Pradesh,   906,672,   809,592,   4.29%,   122.977\n",
      "11,   Kerala,   -,   781,653,   4.14%,   118.733\n",
      "12,   Delhi,   856,112,   774,870,   4.10%,   117.703\n",
      "13,   Haryana,   831,610,   734,163,   3.89%,   111.519\n",
      "14,   Bihar,   611,804,   530,363,   2.81%,   80.562\n",
      "15,   Punjab,   574,760,   526,376,   2.79%,   79.957\n",
      "16,   Odisha,   521,275,   487,805,   2.58%,   74.098\n",
      "17,   Assam,   -,   315,881,   1.67%,   47.982\n",
      "18,   Chhattisgarh,   329,180,   304,063,   1.61%,   46.187\n",
      "19,   Jharkhand,   328,598,   297,204,   1.57%,   45.145\n",
      "20,   Uttarakhand,   -,   245,895,   1.30%,   37.351\n",
      "21,   Jammu & Kashmir,   -,   155,956,   0.83%,   23.690\n",
      "22,   Himachal Pradesh,   165,472,   153,845,   0.81%,   23.369\n",
      "23,   Goa,   80,449,   73,170,   0.39%,   11.115\n",
      "24,   Tripura,   55,984,   49,845,   0.26%,   7.571\n",
      "25,   Chandigarh,   -,   42,114,   0.22%,   6.397\n",
      "26,   Puducherry,   38,253,   34,433,   0.18%,   5.230\n",
      "27,   Meghalaya,   36,572,   33,481,   0.18%,   5.086\n",
      "28,   Sikkim,   32,496,   28,723,   0.15%,   4.363\n",
      "29,   Manipur,   31,790,   27,870,   0.15%,   4.233\n",
      "30,   Nagaland,   -,   27,283,   0.14%,   4.144\n",
      "31,   Arunachal Pradesh,   -,   24,603,   0.13%,   3.737\n",
      "32,   Mizoram,   26,503,   22,287,   0.12%,   3.385\n",
      "33,   Andaman & Nicobar Islands,   ---,   ---,   ---,   ---\n",
      "  ,   India,   20,351,013,   18,886,957,   2,869,   14,569,268\n",
      "['India', '20,351,013', '18,886,957', '2,869', '14,569,268', '14,003,316', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbodies = soup.find(lambda tag: tag.name=='table' and tag.has_attr('id') and tag['id']==\"table_id\")\n",
    "\n",
    "rows = tbodies.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "for i in range(37):\n",
    "  try:\n",
    "    val = rows[i].text.split('\\n')\n",
    "    if i == 0 :\n",
    "      print(f'{val[0]},   {val[1]},   {val[2]} 19-20 ,   {val[2]} 18-19,  {val[3][0:5]},  {val[3][5:]}')\n",
    "      \n",
    "    elif i == 1:\n",
    "      continue\n",
    "    elif i <10 :\n",
    "      print(f'{i-1},   {val[0][1:]},   {val[1]},   {val[2]},   {val[3]},   {val[4]}')\n",
    "\n",
    "    elif i <=33 :\n",
    "        print(f'{i-1},   {val[0][2:]},   {val[1]},   {val[2]},   {val[3]},   {val[4]}')\n",
    "\n",
    "    elif i == 34:\n",
    "      print(f'{i-1},   {val[0][2:]},   {val[1]},   {val[2]},   {val[2]},   {val[2]}')\n",
    "\n",
    "    elif i == 35:\n",
    "      print(f'  ,   {val[0]},   {val[1]},   {val[2]},   {val[3]},   {val[4]}')\n",
    "  except Exception as e:\n",
    "    pass\n",
    "  \n",
    "val = rows[35].text.split('\\n')\n",
    "print(val)\n",
    "val[2]\n",
    "len(val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#   if dump.status_code == 200:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nbformat': 4,\n",
       " 'nbformat_minor': 0,\n",
       " 'metadata': {'colab': {'name': 'Q6.ipynb', 'provenance': []},\n",
       "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
       "  'language_info': {'name': 'python'}},\n",
       " 'cells': [{'cell_type': 'code',\n",
       "   'metadata': {'id': 'nmI4cRjpJh4B'},\n",
       "   'source': ['import requests\\n', 'from bs4 import BeautifulSoup as bs\\n'],\n",
       "   'execution_count': 1,\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': '5qnNu5fELg62',\n",
       "    'outputId': '5eb3031c-d6a8-4055-99d8-af15a577f4a1'},\n",
       "   'source': [\"url = 'https://www.billboard.com/charts/hot-100'\\n\",\n",
       "    '\\n',\n",
       "    'dump = requests.get(url)\\n',\n",
       "    '\\n',\n",
       "    \"soup = bs(dump.content,'html.parser')\\n\",\n",
       "    '\\n',\n",
       "    '\\n'],\n",
       "   'execution_count': 55,\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'data': {'text/plain': ['200']},\n",
       "     'metadata': {'tags': []},\n",
       "     'execution_count': 55}]},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': 'VltSc14_Mnkd',\n",
       "    'outputId': '57456379-5356-4083-94d3-4ca5e798b9b8'},\n",
       "   'source': [\"tbodies = soup.find('ol',{'class':'chart-list__elements'})\\n\",\n",
       "    '\\n',\n",
       "    \"li = tbodies.find_all('li')\\n\",\n",
       "    '\\n',\n",
       "    'def main():\\n',\n",
       "    '  if dump.status_code == 200:\\n',\n",
       "    '    for i in range(100):\\n',\n",
       "    '      \\n',\n",
       "    '        if i == 0 :\\n',\n",
       "    \"          print(f'Song name,Artist name,Last Week Rank,Peak Rank,Weeks On Board')\\n\",\n",
       "    '        li[i]\\n',\n",
       "    \"        name= li[i].find('span',{'class':'chart-element__information__song text--truncate color--primary'}).text\\n\",\n",
       "    \"        artist_name = li[i].find('span',{'class':'chart-element__information__artist text--truncate color--secondary'}).text\\n\",\n",
       "    \"        last_week_rank = li[i].find('span',{'class':'chart-element__information__delta__text text--last'}).text.replace('-','0')\\n\",\n",
       "    \"        peak_rank = li[i].find('span',{'class':'chart-element__information__delta__text text--peak'}).text\\n\",\n",
       "    \"        weeks_on_board = li[i].find('span',{'class':'chart-element__information__delta__text text--week'}).text\\n\",\n",
       "    '\\n',\n",
       "    \"        print(f'{name},{artist_name},{last_week_rank},{peak_rank},{weeks_on_board}')\\n\",\n",
       "    '  else:\\n',\n",
       "    \"    ('Site resource has been changed')\\n\",\n",
       "    '\\n',\n",
       "    \"if __name__=='__main__':\\n\",\n",
       "    '  main()\\n'],\n",
       "   'execution_count': 58,\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'text': ['Song name,Artist name,Last Week Rank,Peak Rank,Weeks On Board\\n',\n",
       "      'Butter,BTS,1 Last Week,1 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Industry Baby,Lil Nas X & Jack Harlow,0 Last Week,2 Peak Rank,1 Weeks on Chart\\n',\n",
       "      'Good 4 U,Olivia Rodrigo,2 Last Week,1 Peak Rank,11 Weeks on Chart\\n',\n",
       "      'Stay,The Kid LAROI & Justin Bieber,4 Last Week,3 Peak Rank,3 Weeks on Chart\\n',\n",
       "      'Levitating,Dua Lipa Featuring DaBaby,3 Last Week,2 Peak Rank,43 Weeks on Chart\\n',\n",
       "      'Kiss Me More,Doja Cat Featuring SZA,5 Last Week,3 Peak Rank,16 Weeks on Chart\\n',\n",
       "      'Bad Habits,Ed Sheeran,6 Last Week,5 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Montero (Call Me By Your Name),Lil Nas X,8 Last Week,1 Peak Rank,18 Weeks on Chart\\n',\n",
       "      'Permission To Dance,BTS,7 Last Week,1 Peak Rank,3 Weeks on Chart\\n',\n",
       "      'Deja Vu,Olivia Rodrigo,9 Last Week,3 Peak Rank,17 Weeks on Chart\\n',\n",
       "      'Save Your Tears,The Weeknd & Ariana Grande,10 Last Week,1 Peak Rank,33 Weeks on Chart\\n',\n",
       "      'Peaches,Justin Bieber Featuring Daniel Caesar & Giveon,11 Last Week,1 Peak Rank,19 Weeks on Chart\\n',\n",
       "      'Leave The Door Open,Silk Sonic (Bruno Mars & Anderson .Paak),12 Last Week,1 Peak Rank,21 Weeks on Chart\\n',\n",
       "      'Fancy Like,Walker Hayes,15 Last Week,14 Peak Rank,6 Weeks on Chart\\n',\n",
       "      \"If I Didn't Love You,Jason Aldean & Carrie Underwood,0 Last Week,15 Peak Rank,1 Weeks on Chart\\n\",\n",
       "      'Rapstar,Polo G,13 Last Week,1 Peak Rank,16 Weeks on Chart\\n',\n",
       "      'Blinding Lights,The Weeknd,17 Last Week,1 Peak Rank,86 Weeks on Chart\\n',\n",
       "      'Heartbreak Anniversary,Giveon,16 Last Week,16 Peak Rank,24 Weeks on Chart\\n',\n",
       "      'You Right,Doja Cat & The Weeknd,19 Last Week,11 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Without You,The Kid LAROI,20 Last Week,8 Peak Rank,34 Weeks on Chart\\n',\n",
       "      'Astronaut In The Ocean,Masked Wolf,18 Last Week,6 Peak Rank,24 Weeks on Chart\\n',\n",
       "      'Forever After All,Luke Combs,21 Last Week,2 Peak Rank,40 Weeks on Chart\\n',\n",
       "      'Every Chance I Get,DJ Khaled Featuring Lil Baby & Lil Durk,22 Last Week,20 Peak Rank,13 Weeks on Chart\\n',\n",
       "      'Leave Before You Love Me,Marshmello X Jonas Brothers,24 Last Week,24 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Lil Bit,Nelly & Florida Georgia Line,26 Last Week,23 Peak Rank,19 Weeks on Chart\\n',\n",
       "      'Single Saturday Night,Cole Swindell,27 Last Week,26 Peak Rank,13 Weeks on Chart\\n',\n",
       "      'Beautiful Mistakes,Maroon 5 Featuring Megan Thee Stallion,29 Last Week,13 Peak Rank,21 Weeks on Chart\\n',\n",
       "      'Thot Shit,Megan Thee Stallion,25 Last Week,16 Peak Rank,7 Weeks on Chart\\n',\n",
       "      'Late At Night,Roddy Ricch,33 Last Week,20 Peak Rank,8 Weeks on Chart\\n',\n",
       "      'Heat Waves,Glass Animals,32 Last Week,19 Peak Rank,28 Weeks on Chart\\n',\n",
       "      'Glad You Exist,Dan + Shay,34 Last Week,31 Peak Rank,25 Weeks on Chart\\n',\n",
       "      \"Drinkin' Beer. Talkin' God. Amen.,Chase Rice Featuring Florida Georgia Line,37 Last Week,32 Peak Rank,9 Weeks on Chart\\n\",\n",
       "      'Motley Crew,Post Malone,23 Last Week,13 Peak Rank,3 Weeks on Chart\\n',\n",
       "      \"Ain't Shit,Doja Cat,31 Last Week,24 Peak Rank,5 Weeks on Chart\\n\",\n",
       "      'Telepatia,Kali Uchis,38 Last Week,25 Peak Rank,23 Weeks on Chart\\n',\n",
       "      'Famous Friends,Chris Young + Kane Brown,28 Last Week,21 Peak Rank,18 Weeks on Chart\\n',\n",
       "      'Need To Know,Doja Cat,46 Last Week,37 Peak Rank,7 Weeks on Chart\\n',\n",
       "      \"Beggin',Maneskin,35 Last Week,35 Peak Rank,5 Weeks on Chart\\n\",\n",
       "      'Whole Lotta Money,BIA Featuring Nicki Minaj,30 Last Week,16 Peak Rank,3 Weeks on Chart\\n',\n",
       "      'Best Friend,Saweetie Featuring Doja Cat,40 Last Week,14 Peak Rank,29 Weeks on Chart\\n',\n",
       "      'Not Sober,The Kid LAROI Featuring Polo G & Stunna Gambino,0 Last Week,41 Peak Rank,1 Weeks on Chart\\n',\n",
       "      \"Don't Go Yet,Camila Cabello,0 Last Week,42 Peak Rank,1 Weeks on Chart\\n\",\n",
       "      'Mood,24kGoldn Featuring iann dior,41 Last Week,1 Peak Rank,51 Weeks on Chart\\n',\n",
       "      \"My Ex's Best Friend,Machine Gun Kelly X blackbear,42 Last Week,20 Peak Rank,50 Weeks on Chart\\n\",\n",
       "      'Wild Side,Normani Featuring Cardi B,14 Last Week,14 Peak Rank,2 Weeks on Chart\\n',\n",
       "      'Wockesha,Moneybagg Yo,48 Last Week,33 Peak Rank,14 Weeks on Chart\\n',\n",
       "      'Traitor,Olivia Rodrigo,39 Last Week,9 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Chasing After You,Ryan Hurd With Maren Morris,58 Last Week,48 Peak Rank,13 Weeks on Chart\\n',\n",
       "      'Wants And Needs,Drake Featuring Lil Baby,47 Last Week,2 Peak Rank,21 Weeks on Chart\\n',\n",
       "      'Yonaguni,Bad Bunny,44 Last Week,10 Peak Rank,8 Weeks on Chart\\n',\n",
       "      'Todo de Ti,Rauw Alejandro,45 Last Week,32 Peak Rank,9 Weeks on Chart\\n',\n",
       "      'Country Again,Thomas Rhett,66 Last Week,52 Peak Rank,13 Weeks on Chart\\n',\n",
       "      'Waves,Luke Bryan,61 Last Week,53 Peak Rank,6 Weeks on Chart\\n',\n",
       "      'Things A Man Oughta Know,Lainey Wilson,51 Last Week,51 Peak Rank,11 Weeks on Chart\\n',\n",
       "      'Arcade,Duncan Laurence,57 Last Week,55 Peak Rank,16 Weeks on Chart\\n',\n",
       "      'One Too Many,Keith Urban Duet With P!nk,55 Last Week,52 Peak Rank,33 Weeks on Chart\\n',\n",
       "      'Over The Top,Smiley Featuring Drake,0 Last Week,57 Peak Rank,1 Weeks on Chart\\n',\n",
       "      'You,Regard x Troye Sivan x Tate McRae,60 Last Week,58 Peak Rank,7 Weeks on Chart\\n',\n",
       "      'Essence,Wizkid Featuring Tems,67 Last Week,59 Peak Rank,4 Weeks on Chart\\n',\n",
       "      'Ball If I Want To,DaBaby,56 Last Week,39 Peak Rank,6 Weeks on Chart\\n',\n",
       "      'Memory,Kane Brown X blackbear,70 Last Week,50 Peak Rank,3 Weeks on Chart\\n',\n",
       "      \"We Didn't Have Much,Justin Moore,65 Last Week,62 Peak Rank,6 Weeks on Chart\\n\",\n",
       "      '2055,Sleepy Hallow,87 Last Week,63 Peak Rank,2 Weeks on Chart\\n',\n",
       "      \"Drunk (And I Don't Wanna Go Home),Elle King & Miranda Lambert,59 Last Week,53 Peak Rank,14 Weeks on Chart\\n\",\n",
       "      'Blame It On You,Jason Aldean,36 Last Week,30 Peak Rank,14 Weeks on Chart\\n',\n",
       "      'Settling Down,Miranda Lambert,53 Last Week,41 Peak Rank,20 Weeks on Chart\\n',\n",
       "      'Gone,Dierks Bentley,63 Last Week,26 Peak Rank,20 Weeks on Chart\\n',\n",
       "      'Way Less Sad,AJR,62 Last Week,54 Peak Rank,14 Weeks on Chart\\n',\n",
       "      'my.life,J. Cole, 21 Savage & Morray,69 Last Week,2 Peak Rank,11 Weeks on Chart\\n',\n",
       "      'A-O-K,Tai Verdes,78 Last Week,70 Peak Rank,4 Weeks on Chart\\n',\n",
       "      'Straightenin,Migos,72 Last Week,23 Peak Rank,11 Weeks on Chart\\n',\n",
       "      'Tombstone,Rod Wave,77 Last Week,11 Peak Rank,18 Weeks on Chart\\n',\n",
       "      'Love Again,Dua Lipa,89 Last Week,73 Peak Rank,2 Weeks on Chart\\n',\n",
       "      'AM,Nio Garcia X J Balvin X Bad Bunny,73 Last Week,41 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Favorite Crime,Olivia Rodrigo,68 Last Week,16 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Come Through,H.E.R. Featuring Chris Brown,84 Last Week,64 Peak Rank,8 Weeks on Chart\\n',\n",
       "      'I Was On A Boat That Day,Old Dominion,90 Last Week,77 Peak Rank,4 Weeks on Chart\\n',\n",
       "      'Cold Beer Calling My Name,Jameson Rodgers Featuring Luke Combs,100 Last Week,78 Peak Rank,4 Weeks on Chart\\n',\n",
       "      'You Should Probably Leave,Chris Stapleton,98 Last Week,79 Peak Rank,4 Weeks on Chart\\n',\n",
       "      'Happier,Olivia Rodrigo,76 Last Week,15 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Pepas,Farruko,0 Last Week,81 Peak Rank,1 Weeks on Chart\\n',\n",
       "      'My Boy,Elvie Shane,95 Last Week,82 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Hats Off,Lil Baby, Lil Durk & Travis Scott,81 Last Week,16 Peak Rank,8 Weeks on Chart\\n',\n",
       "      'Red Light Green Light,DaBaby,79 Last Week,50 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Fiel,Los Legendarios, Wisin & Jhay Cortez,85 Last Week,62 Peak Rank,7 Weeks on Chart\\n',\n",
       "      'Next Girl,Carly Pearce,0 Last Week,86 Peak Rank,2 Weeks on Chart\\n',\n",
       "      'NDA,Billie Eilish,75 Last Week,39 Peak Rank,3 Weeks on Chart\\n',\n",
       "      'Better Believe,Belly, The Weeknd & Young Thug,0 Last Week,88 Peak Rank,1 Weeks on Chart\\n',\n",
       "      'Lick Back,EST Gee,0 Last Week,89 Peak Rank,1 Weeks on Chart\\n',\n",
       "      \"Memory I Don't Mess With,Lee Brice,0 Last Week,90 Peak Rank,1 Weeks on Chart\\n\",\n",
       "      'Ski,Young Thug & Gunna,74 Last Week,18 Peak Rank,15 Weeks on Chart\\n',\n",
       "      '5500 Degrees,EST Gee Featuring Lil Baby, 42 Dugg & Rylo Rodriguez,0 Last Week,92 Peak Rank,1 Weeks on Chart\\n',\n",
       "      'Build A Bitch,Bella Poarch,96 Last Week,56 Peak Rank,11 Weeks on Chart\\n',\n",
       "      'Twerkulator,City Girls,94 Last Week,51 Peak Rank,8 Weeks on Chart\\n',\n",
       "      'Brutal,Olivia Rodrigo,88 Last Week,12 Peak Rank,10 Weeks on Chart\\n',\n",
       "      'Minimum Wage,Blake Shelton,83 Last Week,67 Peak Rank,12 Weeks on Chart\\n',\n",
       "      'Working,Tate McRae X Khalid,0 Last Week,88 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Holy Smokes,Trippie Redd Featuring Lil Uzi Vert,50 Last Week,50 Peak Rank,2 Weeks on Chart\\n',\n",
       "      'WUSYANAME,Tyler, The Creator Featuring YoungBoy Never Broke Again & Ty Dolla $ign,91 Last Week,14 Peak Rank,5 Weeks on Chart\\n',\n",
       "      'Still Chose You,The Kid LAROI Featuring Mustard,0 Last Week,100 Peak Rank,1 Weeks on Chart\\n'],\n",
       "     'name': 'stdout'}]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"name\": \"Q6.ipynb\",\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nmI4cRjpJh4B\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"import requests\\n\",\n",
    "        \"from bs4 import BeautifulSoup as bs\\n\"\n",
    "      ],\n",
    "      \"execution_count\": 1,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"5qnNu5fELg62\",\n",
    "        \"outputId\": \"5eb3031c-d6a8-4055-99d8-af15a577f4a1\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"url = 'https://www.billboard.com/charts/hot-100'\\n\",\n",
    "        \"\\n\",\n",
    "        \"dump = requests.get(url)\\n\",\n",
    "        \"\\n\",\n",
    "        \"soup = bs(dump.content,'html.parser')\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\"\n",
    "      ],\n",
    "      \"execution_count\": 55,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"execute_result\",\n",
    "          \"data\": {\n",
    "            \"text/plain\": [\n",
    "              \"200\"\n",
    "            ]\n",
    "          },\n",
    "          \"metadata\": {\n",
    "            \"tags\": []\n",
    "          },\n",
    "          \"execution_count\": 55\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"VltSc14_Mnkd\",\n",
    "        \"outputId\": \"57456379-5356-4083-94d3-4ca5e798b9b8\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"tbodies = soup.find('ol',{'class':'chart-list__elements'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"li = tbodies.find_all('li')\\n\",\n",
    "        \"\\n\",\n",
    "        \"def main():\\n\",\n",
    "        \"  if dump.status_code == 200:\\n\",\n",
    "        \"    for i in range(100):\\n\",\n",
    "        \"      \\n\",\n",
    "        \"        if i == 0 :\\n\",\n",
    "        \"          print(f'Song name,Artist name,Last Week Rank,Peak Rank,Weeks On Board')\\n\",\n",
    "        \"        li[i]\\n\",\n",
    "        \"        name= li[i].find('span',{'class':'chart-element__information__song text--truncate color--primary'}).text\\n\",\n",
    "        \"        artist_name = li[i].find('span',{'class':'chart-element__information__artist text--truncate color--secondary'}).text\\n\",\n",
    "        \"        last_week_rank = li[i].find('span',{'class':'chart-element__information__delta__text text--last'}).text.replace('-','0')\\n\",\n",
    "        \"        peak_rank = li[i].find('span',{'class':'chart-element__information__delta__text text--peak'}).text\\n\",\n",
    "        \"        weeks_on_board = li[i].find('span',{'class':'chart-element__information__delta__text text--week'}).text\\n\",\n",
    "        \"\\n\",\n",
    "        \"        print(f'{name},{artist_name},{last_week_rank},{peak_rank},{weeks_on_board}')\\n\",\n",
    "        \"  else:\\n\",\n",
    "        \"    ('Site resource has been changed')\\n\",\n",
    "        \"\\n\",\n",
    "        \"if __name__=='__main__':\\n\",\n",
    "        \"  main()\\n\"\n",
    "      ],\n",
    "      \"execution_count\": 58,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"Song name,Artist name,Last Week Rank,Peak Rank,Weeks On Board\\n\",\n",
    "            \"Butter,BTS,1 Last Week,1 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Industry Baby,Lil Nas X & Jack Harlow,0 Last Week,2 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Good 4 U,Olivia Rodrigo,2 Last Week,1 Peak Rank,11 Weeks on Chart\\n\",\n",
    "            \"Stay,The Kid LAROI & Justin Bieber,4 Last Week,3 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"Levitating,Dua Lipa Featuring DaBaby,3 Last Week,2 Peak Rank,43 Weeks on Chart\\n\",\n",
    "            \"Kiss Me More,Doja Cat Featuring SZA,5 Last Week,3 Peak Rank,16 Weeks on Chart\\n\",\n",
    "            \"Bad Habits,Ed Sheeran,6 Last Week,5 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Montero (Call Me By Your Name),Lil Nas X,8 Last Week,1 Peak Rank,18 Weeks on Chart\\n\",\n",
    "            \"Permission To Dance,BTS,7 Last Week,1 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"Deja Vu,Olivia Rodrigo,9 Last Week,3 Peak Rank,17 Weeks on Chart\\n\",\n",
    "            \"Save Your Tears,The Weeknd & Ariana Grande,10 Last Week,1 Peak Rank,33 Weeks on Chart\\n\",\n",
    "            \"Peaches,Justin Bieber Featuring Daniel Caesar & Giveon,11 Last Week,1 Peak Rank,19 Weeks on Chart\\n\",\n",
    "            \"Leave The Door Open,Silk Sonic (Bruno Mars & Anderson .Paak),12 Last Week,1 Peak Rank,21 Weeks on Chart\\n\",\n",
    "            \"Fancy Like,Walker Hayes,15 Last Week,14 Peak Rank,6 Weeks on Chart\\n\",\n",
    "            \"If I Didn't Love You,Jason Aldean & Carrie Underwood,0 Last Week,15 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Rapstar,Polo G,13 Last Week,1 Peak Rank,16 Weeks on Chart\\n\",\n",
    "            \"Blinding Lights,The Weeknd,17 Last Week,1 Peak Rank,86 Weeks on Chart\\n\",\n",
    "            \"Heartbreak Anniversary,Giveon,16 Last Week,16 Peak Rank,24 Weeks on Chart\\n\",\n",
    "            \"You Right,Doja Cat & The Weeknd,19 Last Week,11 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Without You,The Kid LAROI,20 Last Week,8 Peak Rank,34 Weeks on Chart\\n\",\n",
    "            \"Astronaut In The Ocean,Masked Wolf,18 Last Week,6 Peak Rank,24 Weeks on Chart\\n\",\n",
    "            \"Forever After All,Luke Combs,21 Last Week,2 Peak Rank,40 Weeks on Chart\\n\",\n",
    "            \"Every Chance I Get,DJ Khaled Featuring Lil Baby & Lil Durk,22 Last Week,20 Peak Rank,13 Weeks on Chart\\n\",\n",
    "            \"Leave Before You Love Me,Marshmello X Jonas Brothers,24 Last Week,24 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Lil Bit,Nelly & Florida Georgia Line,26 Last Week,23 Peak Rank,19 Weeks on Chart\\n\",\n",
    "            \"Single Saturday Night,Cole Swindell,27 Last Week,26 Peak Rank,13 Weeks on Chart\\n\",\n",
    "            \"Beautiful Mistakes,Maroon 5 Featuring Megan Thee Stallion,29 Last Week,13 Peak Rank,21 Weeks on Chart\\n\",\n",
    "            \"Thot Shit,Megan Thee Stallion,25 Last Week,16 Peak Rank,7 Weeks on Chart\\n\",\n",
    "            \"Late At Night,Roddy Ricch,33 Last Week,20 Peak Rank,8 Weeks on Chart\\n\",\n",
    "            \"Heat Waves,Glass Animals,32 Last Week,19 Peak Rank,28 Weeks on Chart\\n\",\n",
    "            \"Glad You Exist,Dan + Shay,34 Last Week,31 Peak Rank,25 Weeks on Chart\\n\",\n",
    "            \"Drinkin' Beer. Talkin' God. Amen.,Chase Rice Featuring Florida Georgia Line,37 Last Week,32 Peak Rank,9 Weeks on Chart\\n\",\n",
    "            \"Motley Crew,Post Malone,23 Last Week,13 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"Ain't Shit,Doja Cat,31 Last Week,24 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Telepatia,Kali Uchis,38 Last Week,25 Peak Rank,23 Weeks on Chart\\n\",\n",
    "            \"Famous Friends,Chris Young + Kane Brown,28 Last Week,21 Peak Rank,18 Weeks on Chart\\n\",\n",
    "            \"Need To Know,Doja Cat,46 Last Week,37 Peak Rank,7 Weeks on Chart\\n\",\n",
    "            \"Beggin',Maneskin,35 Last Week,35 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Whole Lotta Money,BIA Featuring Nicki Minaj,30 Last Week,16 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"Best Friend,Saweetie Featuring Doja Cat,40 Last Week,14 Peak Rank,29 Weeks on Chart\\n\",\n",
    "            \"Not Sober,The Kid LAROI Featuring Polo G & Stunna Gambino,0 Last Week,41 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Don't Go Yet,Camila Cabello,0 Last Week,42 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Mood,24kGoldn Featuring iann dior,41 Last Week,1 Peak Rank,51 Weeks on Chart\\n\",\n",
    "            \"My Ex's Best Friend,Machine Gun Kelly X blackbear,42 Last Week,20 Peak Rank,50 Weeks on Chart\\n\",\n",
    "            \"Wild Side,Normani Featuring Cardi B,14 Last Week,14 Peak Rank,2 Weeks on Chart\\n\",\n",
    "            \"Wockesha,Moneybagg Yo,48 Last Week,33 Peak Rank,14 Weeks on Chart\\n\",\n",
    "            \"Traitor,Olivia Rodrigo,39 Last Week,9 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Chasing After You,Ryan Hurd With Maren Morris,58 Last Week,48 Peak Rank,13 Weeks on Chart\\n\",\n",
    "            \"Wants And Needs,Drake Featuring Lil Baby,47 Last Week,2 Peak Rank,21 Weeks on Chart\\n\",\n",
    "            \"Yonaguni,Bad Bunny,44 Last Week,10 Peak Rank,8 Weeks on Chart\\n\",\n",
    "            \"Todo de Ti,Rauw Alejandro,45 Last Week,32 Peak Rank,9 Weeks on Chart\\n\",\n",
    "            \"Country Again,Thomas Rhett,66 Last Week,52 Peak Rank,13 Weeks on Chart\\n\",\n",
    "            \"Waves,Luke Bryan,61 Last Week,53 Peak Rank,6 Weeks on Chart\\n\",\n",
    "            \"Things A Man Oughta Know,Lainey Wilson,51 Last Week,51 Peak Rank,11 Weeks on Chart\\n\",\n",
    "            \"Arcade,Duncan Laurence,57 Last Week,55 Peak Rank,16 Weeks on Chart\\n\",\n",
    "            \"One Too Many,Keith Urban Duet With P!nk,55 Last Week,52 Peak Rank,33 Weeks on Chart\\n\",\n",
    "            \"Over The Top,Smiley Featuring Drake,0 Last Week,57 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"You,Regard x Troye Sivan x Tate McRae,60 Last Week,58 Peak Rank,7 Weeks on Chart\\n\",\n",
    "            \"Essence,Wizkid Featuring Tems,67 Last Week,59 Peak Rank,4 Weeks on Chart\\n\",\n",
    "            \"Ball If I Want To,DaBaby,56 Last Week,39 Peak Rank,6 Weeks on Chart\\n\",\n",
    "            \"Memory,Kane Brown X blackbear,70 Last Week,50 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"We Didn't Have Much,Justin Moore,65 Last Week,62 Peak Rank,6 Weeks on Chart\\n\",\n",
    "            \"2055,Sleepy Hallow,87 Last Week,63 Peak Rank,2 Weeks on Chart\\n\",\n",
    "            \"Drunk (And I Don't Wanna Go Home),Elle King & Miranda Lambert,59 Last Week,53 Peak Rank,14 Weeks on Chart\\n\",\n",
    "            \"Blame It On You,Jason Aldean,36 Last Week,30 Peak Rank,14 Weeks on Chart\\n\",\n",
    "            \"Settling Down,Miranda Lambert,53 Last Week,41 Peak Rank,20 Weeks on Chart\\n\",\n",
    "            \"Gone,Dierks Bentley,63 Last Week,26 Peak Rank,20 Weeks on Chart\\n\",\n",
    "            \"Way Less Sad,AJR,62 Last Week,54 Peak Rank,14 Weeks on Chart\\n\",\n",
    "            \"my.life,J. Cole, 21 Savage & Morray,69 Last Week,2 Peak Rank,11 Weeks on Chart\\n\",\n",
    "            \"A-O-K,Tai Verdes,78 Last Week,70 Peak Rank,4 Weeks on Chart\\n\",\n",
    "            \"Straightenin,Migos,72 Last Week,23 Peak Rank,11 Weeks on Chart\\n\",\n",
    "            \"Tombstone,Rod Wave,77 Last Week,11 Peak Rank,18 Weeks on Chart\\n\",\n",
    "            \"Love Again,Dua Lipa,89 Last Week,73 Peak Rank,2 Weeks on Chart\\n\",\n",
    "            \"AM,Nio Garcia X J Balvin X Bad Bunny,73 Last Week,41 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Favorite Crime,Olivia Rodrigo,68 Last Week,16 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Come Through,H.E.R. Featuring Chris Brown,84 Last Week,64 Peak Rank,8 Weeks on Chart\\n\",\n",
    "            \"I Was On A Boat That Day,Old Dominion,90 Last Week,77 Peak Rank,4 Weeks on Chart\\n\",\n",
    "            \"Cold Beer Calling My Name,Jameson Rodgers Featuring Luke Combs,100 Last Week,78 Peak Rank,4 Weeks on Chart\\n\",\n",
    "            \"You Should Probably Leave,Chris Stapleton,98 Last Week,79 Peak Rank,4 Weeks on Chart\\n\",\n",
    "            \"Happier,Olivia Rodrigo,76 Last Week,15 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Pepas,Farruko,0 Last Week,81 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"My Boy,Elvie Shane,95 Last Week,82 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Hats Off,Lil Baby, Lil Durk & Travis Scott,81 Last Week,16 Peak Rank,8 Weeks on Chart\\n\",\n",
    "            \"Red Light Green Light,DaBaby,79 Last Week,50 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Fiel,Los Legendarios, Wisin & Jhay Cortez,85 Last Week,62 Peak Rank,7 Weeks on Chart\\n\",\n",
    "            \"Next Girl,Carly Pearce,0 Last Week,86 Peak Rank,2 Weeks on Chart\\n\",\n",
    "            \"NDA,Billie Eilish,75 Last Week,39 Peak Rank,3 Weeks on Chart\\n\",\n",
    "            \"Better Believe,Belly, The Weeknd & Young Thug,0 Last Week,88 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Lick Back,EST Gee,0 Last Week,89 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Memory I Don't Mess With,Lee Brice,0 Last Week,90 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Ski,Young Thug & Gunna,74 Last Week,18 Peak Rank,15 Weeks on Chart\\n\",\n",
    "            \"5500 Degrees,EST Gee Featuring Lil Baby, 42 Dugg & Rylo Rodriguez,0 Last Week,92 Peak Rank,1 Weeks on Chart\\n\",\n",
    "            \"Build A Bitch,Bella Poarch,96 Last Week,56 Peak Rank,11 Weeks on Chart\\n\",\n",
    "            \"Twerkulator,City Girls,94 Last Week,51 Peak Rank,8 Weeks on Chart\\n\",\n",
    "            \"Brutal,Olivia Rodrigo,88 Last Week,12 Peak Rank,10 Weeks on Chart\\n\",\n",
    "            \"Minimum Wage,Blake Shelton,83 Last Week,67 Peak Rank,12 Weeks on Chart\\n\",\n",
    "            \"Working,Tate McRae X Khalid,0 Last Week,88 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Holy Smokes,Trippie Redd Featuring Lil Uzi Vert,50 Last Week,50 Peak Rank,2 Weeks on Chart\\n\",\n",
    "            \"WUSYANAME,Tyler, The Creator Featuring YoungBoy Never Broke Again & Ty Dolla $ign,91 Last Week,14 Peak Rank,5 Weeks on Chart\\n\",\n",
    "            \"Still Chose You,The Kid LAROI Featuring Mustard,0 Last Week,100 Peak Rank,1 Weeks on Chart\\n\"\n",
    "          ],\n",
    "          \"name\": \"stdout\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nbformat': 4,\n",
       " 'nbformat_minor': 0,\n",
       " 'metadata': {'colab': {'name': 'Q7.ipynb', 'provenance': []},\n",
       "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
       "  'language_info': {'name': 'python'}},\n",
       " 'cells': [{'cell_type': 'code',\n",
       "   'metadata': {'id': 'nmI4cRjpJh4B'},\n",
       "   'source': ['import requests\\n', 'from bs4 import BeautifulSoup as bs\\n'],\n",
       "   'execution_count': 144,\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'id': 'AAuvdeDhpQQm'},\n",
       "   'source': ['def npage():\\n',\n",
       "    \"  t = soup.find('div',{'class':'pagination'})\\n\",\n",
       "    '\\n',\n",
       "    \"  if soup.find('div',{'class':'pagination'}).text.strip() == 'Next':\\n\",\n",
       "    '    \\n',\n",
       "    \"    link = t.find('button').attrs.get('onclick')\\n\",\n",
       "    '    url = link.split(\\' \\')[0].split(\"\\'\")[1]\\n',\n",
       "    \"    # print('working')\\n\",\n",
       "    '    return url\\n',\n",
       "    '  else:\\n',\n",
       "    \"    r = 'Last'\\n\",\n",
       "    '    # print(r)\\n',\n",
       "    '    return r'],\n",
       "   'execution_count': 148,\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': 'i7kexruFtfqe',\n",
       "    'outputId': '31d6faf9-e02d-4679-c21c-39a58a9caedc'},\n",
       "   'source': [\"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
       "    '\\n',\n",
       "    'dump = requests.get(url)\\n',\n",
       "    '\\n',\n",
       "    \"soup = bs(dump.content,'html.parser')\\n\",\n",
       "    '\\n',\n",
       "    \"tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
       "    '\\n',\n",
       "    \"li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
       "    'npage()'],\n",
       "   'execution_count': 147,\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'text': ['working\\n'],\n",
       "     'name': 'stdout'}]},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': 'VltSc14_Mnkd',\n",
       "    'outputId': '2a89bb87-5cab-4804-8c2f-e92b320c4179'},\n",
       "   'source': [\"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
       "    'def maion(url):\\n',\n",
       "    '\\n',\n",
       "    '  if url == \"Last\":\\n',\n",
       "    '    print(\"Done\")\\n',\n",
       "    '  else:\\n',\n",
       "    '\\n',\n",
       "    '    dump = requests.get(url)\\n',\n",
       "    '\\n',\n",
       "    \"    soup = bs(dump.content,'html.parser')\\n\",\n",
       "    '\\n',\n",
       "    \"    tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
       "    '\\n',\n",
       "    \"    li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
       "    '\\n',\n",
       "    '    \\n',\n",
       "    '    for i in range(len(li)):\\n',\n",
       "    '      if i == 0 :\\n',\n",
       "    \"        print(f'Name, Designation, Company, Skills Needed, Location')\\n\",\n",
       "    '\\n',\n",
       "    \"      name = li[i].find('span',{'class':'fl ellipsis'}).text\\n\",\n",
       "    \"      des = li[i].find('span',{'class':'ellipsis clr'}).text\\n\",\n",
       "    \"      com = li[i].find_all('a',{'class':'ellipsis'})[1].attrs['title']\\n\",\n",
       "    \"      skills = li[i].find('div',{'class':'hireSec highlightable'}).text\\n\",\n",
       "    '      \\n',\n",
       "    \"      lov = li[i].find('small',{'class':'ellipsis'}).text\\n\",\n",
       "    '          \\n',\n",
       "    '      \\n',\n",
       "    '\\n',\n",
       "    \"      print(f'{name},{des},{com},{skills}.{lov}')\\n\",\n",
       "    '      \\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    \"if __name__=='__main__':\\n\",\n",
       "    '  maion(url)'],\n",
       "   'execution_count': 155,\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'text': ['Name, Designation, Company, Skills Needed, Location\\n',\n",
       "      'Aakash Harit,HR Manager,Data Science Network,    Classic ASP Developer,   Internet Marketing Professional,   Data Science SME,   Content Writers,   SEO Professional,   Revenue Professional    .Delhi\\n',\n",
       "      'MARSIAN Technologies LLP,Company HR,MARSIAN Technologies LLP,    Data Science,   Artificial Intelligence,   Machine Learning,   Business Analytics    .Pune\\n',\n",
       "      'subhas patel,Founder CEO,LibraryXProject,    Hadoop,   Spark,   Digital Strategy,   Data Architecture,   Command Center,   Cdp,   Dmp,   Kafka,   Data Science,   Data Analysis,   Big Data Analytics,   Real Time Analysis,   SQL    .UK - (london)\\n',\n",
       "      'Institute for Financial Management and Resear,Programme Manager,IFMR,    Data Science    .Chennai\\n',\n",
       "      'Asif Lucknowi,Director,Weupskill- Live Wire India,    Technical Training,   Software Development,   Presentation Skills,   B.tech,   M.tech,   B.e.,   mca,   msc,   Computer Science,   freshers,   jobs in indore,   Data Science,   itil    .Indore\\n',\n",
       "      'Priyanka Akiri,HR Manager,Infinitive Software Solutions Pvt.Ltd.,    Oracle Dba,   Data Science,   Data Warehousing,   ETL,   Jupyter,   Numpy,   Data Transformation,   Snowflake,   Teradata,   Python,   Data Manipulation,   Relational Databases    .Hyderabad\\n',\n",
       "      'Mubarak,Company HR,MoneyTap,    Business Intelligence,   Data Warehousing,   Data Science,   Business Analytics,   Customer Support,   Business Reporting,   Bi    .Bengaluru / Bangalore\\n',\n",
       "      'Ruchi Dhote,Senior Executive Talent Acquisition,Bristlecone India Ltd,    Qlikview,   Qlik Sense,   Microsoft Azure,   Power Bi,   Data Science,   Machine Learning    .Pune\\n',\n",
       "      'Kapil Devang,HR Manager,BISP Solutions,    Big Data,   Hadoop,   Data Analytics,   Data Science    .Bhopal\\n',\n",
       "      'Riya Rajesh,Manager Talent Acquisition,Novelworx Digital Solutions,    Data Science    .Cochin\\n',\n",
       "      'Faizan Kareem,HR MANAGER,FirstTech Consaltants Pvt.Ltd,    Data Analytics,   Data Science,   Machine Learning,   Deep Learning,   Nlp,   Data Mining,   Python,   R,   Database Administration,   Text Mining    .Hyderabad / Secunderabad\\n',\n",
       "      'Sandhya Khandagale,HR Recruiter,Compumatrice Multimedia Pvt Ltd,    Big Data,   Data Science,   Artificial Intelligence,   Hadoop,   Ui Development,   Php,   Freelancing,   .Net,   Software Testing,   Sap,   Leadership Hiring    .Pune\\n',\n",
       "      'Azahar Shaikh,Company Recruiter,NEAL ANALYTICS SERVICES PVT LTD,    Data Science,   Artificial Intelligence,   Machine Learning,   Data Analytics    .Pune\\n',\n",
       "      'kumar,Proprietor,trainin,    Data Science,   Hadoop,   Rpas,   Devops,   Python,   Aws,   Teaching,   Big Data    .Bengaluru / Bangalore\\n',\n",
       "      'Rajat Kumar,Founder CEO,R.S Consultancy &amp; Services,    Web Technologies,   Project Management,   Software Architecture,   Data Science,   Object Oriented Programming,   Computer Science,   Electrical Engineering,   Architecture    .Delhi\\n',\n",
       "      'Dhruv Dev Dubey,Company Recruitment Head,Confidential,    Server Administartion,   Verilog,   Vhdl,   Digital Marketing,   Market Research,   Property Research,   Legal,   It And Non It Recruitment,   Logistics,   Supply Chain,   Bfsi    .Bengaluru / Bangalore\\n',\n",
       "      'Radha Manivasagam,HR Executive,Techcovery,    Python,   Artificial Intelligence,   Machine Learning,   Data Science    .Bengaluru / Bangalore\\n',\n",
       "      'Amit Sharma,Consultant,ASCO consulting,    Machine Learning,   Artificial Intelligence,   Data Science,   Software Engineering,   Software Development,   Graduate Engineer Trainee,   Fresher,   Data Analytics,   Java    .New Delhi\\n',\n",
       "      'Shashikant Chaudhary,HR Recruiter/HR Excutive,3D India Staffing Research &amp; Consulting Co. India,    Relationship Management,   Retail Sales,   Private Banking,   Mutual Funds,   NISM,   Equity,   Finance,   Financial Products,   Financial Services,   Verbal,   Written    .Aligarh\\n',\n",
       "      'Rutuja Pawar,Technical Recruiter,Demand Matrix,    Data Science,   Big Data Analytics,   Digital Marketing,   Content Writing,   Ui Development,   Database Development,   Qa Automation,   Python,   Project Management    .Pune\\n',\n",
       "      'Ankit Sinha,Head Analytics,Suntech Global,    B.Tech,   Tableau,   Statistics,   R,   Analytics,   Time Series,   Data Science,   Business Solutions,   SQL,   Technical Skills,   SSAS,   SQL Server,   Analysis Services,   Qlikview    .Mumbai\\n',\n",
       "      'Rashi Kacker,Sr Product Manager,Impel Labs Pvt. Ltd.,    Data Science,   Node.js,   Angularjs    .Bengaluru / Bangalore\\n',\n",
       "      'Balaji Kolli,Co Founder,Saras Solutions India Pvt Ltd,    Data Analysis,   Learning,   Data Science,   Computer Science,   Communication Skills    .Hyderabad / Secunderabad\\n',\n",
       "      'ROHIT Kumar,Architect,LNT Private Limited,    Software Development,   Core Java,   Unit Testing,   Customer Experience,   Problem Solving,   Communication Skills,   Mysql,   Data Science,   Sales Management,   Analytics    .Mumbai\\n',\n",
       "      'Shailja Mishra,HR Manager,Certybox Pvt.Ltd.,    consulting,   Education Counseling,   Educational Sales,   Institutional Sales,   pmp,   Data Science,   Business Development,   Revenue Generation,   Sales Achievement,   new    .Noida\\n'],\n",
       "     'name': 'stdout'}]}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"name\": \"Q7.ipynb\",\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nmI4cRjpJh4B\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"import requests\\n\",\n",
    "        \"from bs4 import BeautifulSoup as bs\\n\"\n",
    "      ],\n",
    "      \"execution_count\": 144,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"AAuvdeDhpQQm\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"def npage():\\n\",\n",
    "        \"  t = soup.find('div',{'class':'pagination'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"  if soup.find('div',{'class':'pagination'}).text.strip() == 'Next':\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    link = t.find('button').attrs.get('onclick')\\n\",\n",
    "        \"    url = link.split(' ')[0].split(\\\"'\\\")[1]\\n\",\n",
    "        \"    # print('working')\\n\",\n",
    "        \"    return url\\n\",\n",
    "        \"  else:\\n\",\n",
    "        \"    r = 'Last'\\n\",\n",
    "        \"    # print(r)\\n\",\n",
    "        \"    return r\"\n",
    "      ],\n",
    "      \"execution_count\": 148,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"i7kexruFtfqe\",\n",
    "        \"outputId\": \"31d6faf9-e02d-4679-c21c-39a58a9caedc\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
    "        \"\\n\",\n",
    "        \"dump = requests.get(url)\\n\",\n",
    "        \"\\n\",\n",
    "        \"soup = bs(dump.content,'html.parser')\\n\",\n",
    "        \"\\n\",\n",
    "        \"tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
    "        \"npage()\"\n",
    "      ],\n",
    "      \"execution_count\": 147,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"working\\n\"\n",
    "          ],\n",
    "          \"name\": \"stdout\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"VltSc14_Mnkd\",\n",
    "        \"outputId\": \"2a89bb87-5cab-4804-8c2f-e92b320c4179\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
    "        \"def maion(url):\\n\",\n",
    "        \"\\n\",\n",
    "        \"  if url == \\\"Last\\\":\\n\",\n",
    "        \"    print(\\\"Done\\\")\\n\",\n",
    "        \"  else:\\n\",\n",
    "        \"\\n\",\n",
    "        \"    dump = requests.get(url)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    soup = bs(dump.content,'html.parser')\\n\",\n",
    "        \"\\n\",\n",
    "        \"    tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"    li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    for i in range(len(li)):\\n\",\n",
    "        \"      if i == 0 :\\n\",\n",
    "        \"        print(f'Name, Designation, Company, Skills Needed, Location')\\n\",\n",
    "        \"\\n\",\n",
    "        \"      name = li[i].find('span',{'class':'fl ellipsis'}).text\\n\",\n",
    "        \"      des = li[i].find('span',{'class':'ellipsis clr'}).text\\n\",\n",
    "        \"      com = li[i].find_all('a',{'class':'ellipsis'})[1].attrs['title']\\n\",\n",
    "        \"      skills = li[i].find('div',{'class':'hireSec highlightable'}).text\\n\",\n",
    "        \"      \\n\",\n",
    "        \"      lov = li[i].find('small',{'class':'ellipsis'}).text\\n\",\n",
    "        \"          \\n\",\n",
    "        \"      \\n\",\n",
    "        \"\\n\",\n",
    "        \"      print(f'{name},{des},{com},{skills}.{lov}')\\n\",\n",
    "        \"      \\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"if __name__=='__main__':\\n\",\n",
    "        \"  maion(url)\"\n",
    "      ],\n",
    "      \"execution_count\": 155,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"Name, Designation, Company, Skills Needed, Location\\n\",\n",
    "            \"Aakash Harit,HR Manager,Data Science Network,    Classic ASP Developer,   Internet Marketing Professional,   Data Science SME,   Content Writers,   SEO Professional,   Revenue Professional    .Delhi\\n\",\n",
    "            \"MARSIAN Technologies LLP,Company HR,MARSIAN Technologies LLP,    Data Science,   Artificial Intelligence,   Machine Learning,   Business Analytics    .Pune\\n\",\n",
    "            \"subhas patel,Founder CEO,LibraryXProject,    Hadoop,   Spark,   Digital Strategy,   Data Architecture,   Command Center,   Cdp,   Dmp,   Kafka,   Data Science,   Data Analysis,   Big Data Analytics,   Real Time Analysis,   SQL    .UK - (london)\\n\",\n",
    "            \"Institute for Financial Management and Resear,Programme Manager,IFMR,    Data Science    .Chennai\\n\",\n",
    "            \"Asif Lucknowi,Director,Weupskill- Live Wire India,    Technical Training,   Software Development,   Presentation Skills,   B.tech,   M.tech,   B.e.,   mca,   msc,   Computer Science,   freshers,   jobs in indore,   Data Science,   itil    .Indore\\n\",\n",
    "            \"Priyanka Akiri,HR Manager,Infinitive Software Solutions Pvt.Ltd.,    Oracle Dba,   Data Science,   Data Warehousing,   ETL,   Jupyter,   Numpy,   Data Transformation,   Snowflake,   Teradata,   Python,   Data Manipulation,   Relational Databases    .Hyderabad\\n\",\n",
    "            \"Mubarak,Company HR,MoneyTap,    Business Intelligence,   Data Warehousing,   Data Science,   Business Analytics,   Customer Support,   Business Reporting,   Bi    .Bengaluru / Bangalore\\n\",\n",
    "            \"Ruchi Dhote,Senior Executive Talent Acquisition,Bristlecone India Ltd,    Qlikview,   Qlik Sense,   Microsoft Azure,   Power Bi,   Data Science,   Machine Learning    .Pune\\n\",\n",
    "            \"Kapil Devang,HR Manager,BISP Solutions,    Big Data,   Hadoop,   Data Analytics,   Data Science    .Bhopal\\n\",\n",
    "            \"Riya Rajesh,Manager Talent Acquisition,Novelworx Digital Solutions,    Data Science    .Cochin\\n\",\n",
    "            \"Faizan Kareem,HR MANAGER,FirstTech Consaltants Pvt.Ltd,    Data Analytics,   Data Science,   Machine Learning,   Deep Learning,   Nlp,   Data Mining,   Python,   R,   Database Administration,   Text Mining    .Hyderabad / Secunderabad\\n\",\n",
    "            \"Sandhya Khandagale,HR Recruiter,Compumatrice Multimedia Pvt Ltd,    Big Data,   Data Science,   Artificial Intelligence,   Hadoop,   Ui Development,   Php,   Freelancing,   .Net,   Software Testing,   Sap,   Leadership Hiring    .Pune\\n\",\n",
    "            \"Azahar Shaikh,Company Recruiter,NEAL ANALYTICS SERVICES PVT LTD,    Data Science,   Artificial Intelligence,   Machine Learning,   Data Analytics    .Pune\\n\",\n",
    "            \"kumar,Proprietor,trainin,    Data Science,   Hadoop,   Rpas,   Devops,   Python,   Aws,   Teaching,   Big Data    .Bengaluru / Bangalore\\n\",\n",
    "            \"Rajat Kumar,Founder CEO,R.S Consultancy &amp; Services,    Web Technologies,   Project Management,   Software Architecture,   Data Science,   Object Oriented Programming,   Computer Science,   Electrical Engineering,   Architecture    .Delhi\\n\",\n",
    "            \"Dhruv Dev Dubey,Company Recruitment Head,Confidential,    Server Administartion,   Verilog,   Vhdl,   Digital Marketing,   Market Research,   Property Research,   Legal,   It And Non It Recruitment,   Logistics,   Supply Chain,   Bfsi    .Bengaluru / Bangalore\\n\",\n",
    "            \"Radha Manivasagam,HR Executive,Techcovery,    Python,   Artificial Intelligence,   Machine Learning,   Data Science    .Bengaluru / Bangalore\\n\",\n",
    "            \"Amit Sharma,Consultant,ASCO consulting,    Machine Learning,   Artificial Intelligence,   Data Science,   Software Engineering,   Software Development,   Graduate Engineer Trainee,   Fresher,   Data Analytics,   Java    .New Delhi\\n\",\n",
    "            \"Shashikant Chaudhary,HR Recruiter/HR Excutive,3D India Staffing Research &amp; Consulting Co. India,    Relationship Management,   Retail Sales,   Private Banking,   Mutual Funds,   NISM,   Equity,   Finance,   Financial Products,   Financial Services,   Verbal,   Written    .Aligarh\\n\",\n",
    "            \"Rutuja Pawar,Technical Recruiter,Demand Matrix,    Data Science,   Big Data Analytics,   Digital Marketing,   Content Writing,   Ui Development,   Database Development,   Qa Automation,   Python,   Project Management    .Pune\\n\",\n",
    "            \"Ankit Sinha,Head Analytics,Suntech Global,    B.Tech,   Tableau,   Statistics,   R,   Analytics,   Time Series,   Data Science,   Business Solutions,   SQL,   Technical Skills,   SSAS,   SQL Server,   Analysis Services,   Qlikview    .Mumbai\\n\",\n",
    "            \"Rashi Kacker,Sr Product Manager,Impel Labs Pvt. Ltd.,    Data Science,   Node.js,   Angularjs    .Bengaluru / Bangalore\\n\",\n",
    "            \"Balaji Kolli,Co Founder,Saras Solutions India Pvt Ltd,    Data Analysis,   Learning,   Data Science,   Computer Science,   Communication Skills    .Hyderabad / Secunderabad\\n\",\n",
    "            \"ROHIT Kumar,Architect,LNT Private Limited,    Software Development,   Core Java,   Unit Testing,   Customer Experience,   Problem Solving,   Communication Skills,   Mysql,   Data Science,   Sales Management,   Analytics    .Mumbai\\n\",\n",
    "            \"Shailja Mishra,HR Manager,Certybox Pvt.Ltd.,    consulting,   Education Counseling,   Educational Sales,   Institutional Sales,   pmp,   Data Science,   Business Development,   Revenue Generation,   Sales Achievement,   new    .Noida\\n\"\n",
    "          ],\n",
    "          \"name\": \"stdout\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nbformat': 4,\n",
       " 'nbformat_minor': 0,\n",
       " 'metadata': {'colab': {'name': 'Q7.ipynb', 'provenance': []},\n",
       "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
       "  'language_info': {'name': 'python'}},\n",
       " 'cells': [{'cell_type': 'code',\n",
       "   'metadata': {'id': 'nmI4cRjpJh4B'},\n",
       "   'source': ['import requests\\n', 'from bs4 import BeautifulSoup as bs\\n'],\n",
       "   'execution_count': 144,\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'id': 'AAuvdeDhpQQm'},\n",
       "   'source': ['def npage():\\n',\n",
       "    \"  t = soup.find('div',{'class':'pagination'})\\n\",\n",
       "    '\\n',\n",
       "    \"  if soup.find('div',{'class':'pagination'}).text.strip() == 'Next':\\n\",\n",
       "    '    \\n',\n",
       "    \"    link = t.find('button').attrs.get('onclick')\\n\",\n",
       "    '    url = link.split(\\' \\')[0].split(\"\\'\")[1]\\n',\n",
       "    \"    # print('working')\\n\",\n",
       "    '    return url\\n',\n",
       "    '  else:\\n',\n",
       "    \"    r = 'Last'\\n\",\n",
       "    '    # print(r)\\n',\n",
       "    '    return r'],\n",
       "   'execution_count': 148,\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': 'i7kexruFtfqe',\n",
       "    'outputId': '31d6faf9-e02d-4679-c21c-39a58a9caedc'},\n",
       "   'source': [\"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
       "    '\\n',\n",
       "    'dump = requests.get(url)\\n',\n",
       "    '\\n',\n",
       "    \"soup = bs(dump.content,'html.parser')\\n\",\n",
       "    '\\n',\n",
       "    \"tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
       "    '\\n',\n",
       "    \"li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
       "    'npage()'],\n",
       "   'execution_count': 147,\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'text': ['working\\n'],\n",
       "     'name': 'stdout'}]},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
       "    'id': 'VltSc14_Mnkd',\n",
       "    'outputId': '2a89bb87-5cab-4804-8c2f-e92b320c4179'},\n",
       "   'source': [\"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
       "    'def maion(url):\\n',\n",
       "    '\\n',\n",
       "    '  if url == \"Last\":\\n',\n",
       "    '    print(\"Done\")\\n',\n",
       "    '  else:\\n',\n",
       "    '\\n',\n",
       "    '    dump = requests.get(url)\\n',\n",
       "    '\\n',\n",
       "    \"    soup = bs(dump.content,'html.parser')\\n\",\n",
       "    '\\n',\n",
       "    \"    tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
       "    '\\n',\n",
       "    \"    li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
       "    '\\n',\n",
       "    '    \\n',\n",
       "    '    for i in range(len(li)):\\n',\n",
       "    '      if i == 0 :\\n',\n",
       "    \"        print(f'Name, Designation, Company, Skills Needed, Location')\\n\",\n",
       "    '\\n',\n",
       "    \"      name = li[i].find('span',{'class':'fl ellipsis'}).text\\n\",\n",
       "    \"      des = li[i].find('span',{'class':'ellipsis clr'}).text\\n\",\n",
       "    \"      com = li[i].find_all('a',{'class':'ellipsis'})[1].attrs['title']\\n\",\n",
       "    \"      skills = li[i].find('div',{'class':'hireSec highlightable'}).text\\n\",\n",
       "    '      \\n',\n",
       "    \"      lov = li[i].find('small',{'class':'ellipsis'}).text\\n\",\n",
       "    '          \\n',\n",
       "    '      \\n',\n",
       "    '\\n',\n",
       "    \"      print(f'{name},{des},{com},{skills}.{lov}')\\n\",\n",
       "    '      \\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    '\\n',\n",
       "    \"if __name__=='__main__':\\n\",\n",
       "    '  maion(url)'],\n",
       "   'execution_count': 155,\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'text': ['Name, Designation, Company, Skills Needed, Location\\n',\n",
       "      'Aakash Harit,HR Manager,Data Science Network,    Classic ASP Developer,   Internet Marketing Professional,   Data Science SME,   Content Writers,   SEO Professional,   Revenue Professional    .Delhi\\n',\n",
       "      'MARSIAN Technologies LLP,Company HR,MARSIAN Technologies LLP,    Data Science,   Artificial Intelligence,   Machine Learning,   Business Analytics    .Pune\\n',\n",
       "      'subhas patel,Founder CEO,LibraryXProject,    Hadoop,   Spark,   Digital Strategy,   Data Architecture,   Command Center,   Cdp,   Dmp,   Kafka,   Data Science,   Data Analysis,   Big Data Analytics,   Real Time Analysis,   SQL    .UK - (london)\\n',\n",
       "      'Institute for Financial Management and Resear,Programme Manager,IFMR,    Data Science    .Chennai\\n',\n",
       "      'Asif Lucknowi,Director,Weupskill- Live Wire India,    Technical Training,   Software Development,   Presentation Skills,   B.tech,   M.tech,   B.e.,   mca,   msc,   Computer Science,   freshers,   jobs in indore,   Data Science,   itil    .Indore\\n',\n",
       "      'Priyanka Akiri,HR Manager,Infinitive Software Solutions Pvt.Ltd.,    Oracle Dba,   Data Science,   Data Warehousing,   ETL,   Jupyter,   Numpy,   Data Transformation,   Snowflake,   Teradata,   Python,   Data Manipulation,   Relational Databases    .Hyderabad\\n',\n",
       "      'Mubarak,Company HR,MoneyTap,    Business Intelligence,   Data Warehousing,   Data Science,   Business Analytics,   Customer Support,   Business Reporting,   Bi    .Bengaluru / Bangalore\\n',\n",
       "      'Ruchi Dhote,Senior Executive Talent Acquisition,Bristlecone India Ltd,    Qlikview,   Qlik Sense,   Microsoft Azure,   Power Bi,   Data Science,   Machine Learning    .Pune\\n',\n",
       "      'Kapil Devang,HR Manager,BISP Solutions,    Big Data,   Hadoop,   Data Analytics,   Data Science    .Bhopal\\n',\n",
       "      'Riya Rajesh,Manager Talent Acquisition,Novelworx Digital Solutions,    Data Science    .Cochin\\n',\n",
       "      'Faizan Kareem,HR MANAGER,FirstTech Consaltants Pvt.Ltd,    Data Analytics,   Data Science,   Machine Learning,   Deep Learning,   Nlp,   Data Mining,   Python,   R,   Database Administration,   Text Mining    .Hyderabad / Secunderabad\\n',\n",
       "      'Sandhya Khandagale,HR Recruiter,Compumatrice Multimedia Pvt Ltd,    Big Data,   Data Science,   Artificial Intelligence,   Hadoop,   Ui Development,   Php,   Freelancing,   .Net,   Software Testing,   Sap,   Leadership Hiring    .Pune\\n',\n",
       "      'Azahar Shaikh,Company Recruiter,NEAL ANALYTICS SERVICES PVT LTD,    Data Science,   Artificial Intelligence,   Machine Learning,   Data Analytics    .Pune\\n',\n",
       "      'kumar,Proprietor,trainin,    Data Science,   Hadoop,   Rpas,   Devops,   Python,   Aws,   Teaching,   Big Data    .Bengaluru / Bangalore\\n',\n",
       "      'Rajat Kumar,Founder CEO,R.S Consultancy &amp; Services,    Web Technologies,   Project Management,   Software Architecture,   Data Science,   Object Oriented Programming,   Computer Science,   Electrical Engineering,   Architecture    .Delhi\\n',\n",
       "      'Dhruv Dev Dubey,Company Recruitment Head,Confidential,    Server Administartion,   Verilog,   Vhdl,   Digital Marketing,   Market Research,   Property Research,   Legal,   It And Non It Recruitment,   Logistics,   Supply Chain,   Bfsi    .Bengaluru / Bangalore\\n',\n",
       "      'Radha Manivasagam,HR Executive,Techcovery,    Python,   Artificial Intelligence,   Machine Learning,   Data Science    .Bengaluru / Bangalore\\n',\n",
       "      'Amit Sharma,Consultant,ASCO consulting,    Machine Learning,   Artificial Intelligence,   Data Science,   Software Engineering,   Software Development,   Graduate Engineer Trainee,   Fresher,   Data Analytics,   Java    .New Delhi\\n',\n",
       "      'Shashikant Chaudhary,HR Recruiter/HR Excutive,3D India Staffing Research &amp; Consulting Co. India,    Relationship Management,   Retail Sales,   Private Banking,   Mutual Funds,   NISM,   Equity,   Finance,   Financial Products,   Financial Services,   Verbal,   Written    .Aligarh\\n',\n",
       "      'Rutuja Pawar,Technical Recruiter,Demand Matrix,    Data Science,   Big Data Analytics,   Digital Marketing,   Content Writing,   Ui Development,   Database Development,   Qa Automation,   Python,   Project Management    .Pune\\n',\n",
       "      'Ankit Sinha,Head Analytics,Suntech Global,    B.Tech,   Tableau,   Statistics,   R,   Analytics,   Time Series,   Data Science,   Business Solutions,   SQL,   Technical Skills,   SSAS,   SQL Server,   Analysis Services,   Qlikview    .Mumbai\\n',\n",
       "      'Rashi Kacker,Sr Product Manager,Impel Labs Pvt. Ltd.,    Data Science,   Node.js,   Angularjs    .Bengaluru / Bangalore\\n',\n",
       "      'Balaji Kolli,Co Founder,Saras Solutions India Pvt Ltd,    Data Analysis,   Learning,   Data Science,   Computer Science,   Communication Skills    .Hyderabad / Secunderabad\\n',\n",
       "      'ROHIT Kumar,Architect,LNT Private Limited,    Software Development,   Core Java,   Unit Testing,   Customer Experience,   Problem Solving,   Communication Skills,   Mysql,   Data Science,   Sales Management,   Analytics    .Mumbai\\n',\n",
       "      'Shailja Mishra,HR Manager,Certybox Pvt.Ltd.,    consulting,   Education Counseling,   Educational Sales,   Institutional Sales,   pmp,   Data Science,   Business Development,   Revenue Generation,   Sales Achievement,   new    .Noida\\n'],\n",
       "     'name': 'stdout'}]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"name\": \"Q7.ipynb\",\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nmI4cRjpJh4B\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"import requests\\n\",\n",
    "        \"from bs4 import BeautifulSoup as bs\\n\"\n",
    "      ],\n",
    "      \"execution_count\": 144,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"AAuvdeDhpQQm\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"def npage():\\n\",\n",
    "        \"  t = soup.find('div',{'class':'pagination'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"  if soup.find('div',{'class':'pagination'}).text.strip() == 'Next':\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    link = t.find('button').attrs.get('onclick')\\n\",\n",
    "        \"    url = link.split(' ')[0].split(\\\"'\\\")[1]\\n\",\n",
    "        \"    # print('working')\\n\",\n",
    "        \"    return url\\n\",\n",
    "        \"  else:\\n\",\n",
    "        \"    r = 'Last'\\n\",\n",
    "        \"    # print(r)\\n\",\n",
    "        \"    return r\"\n",
    "      ],\n",
    "      \"execution_count\": 148,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"i7kexruFtfqe\",\n",
    "        \"outputId\": \"31d6faf9-e02d-4679-c21c-39a58a9caedc\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
    "        \"\\n\",\n",
    "        \"dump = requests.get(url)\\n\",\n",
    "        \"\\n\",\n",
    "        \"soup = bs(dump.content,'html.parser')\\n\",\n",
    "        \"\\n\",\n",
    "        \"tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
    "        \"npage()\"\n",
    "      ],\n",
    "      \"execution_count\": 147,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"working\\n\"\n",
    "          ],\n",
    "          \"name\": \"stdout\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"VltSc14_Mnkd\",\n",
    "        \"outputId\": \"2a89bb87-5cab-4804-8c2f-e92b320c4179\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"url = 'https://www.naukri.com/data-science-recruiters?xz=1_0_0&xid=162818491249282200'\\n\",\n",
    "        \"def maion(url):\\n\",\n",
    "        \"\\n\",\n",
    "        \"  if url == \\\"Last\\\":\\n\",\n",
    "        \"    print(\\\"Done\\\")\\n\",\n",
    "        \"  else:\\n\",\n",
    "        \"\\n\",\n",
    "        \"    dump = requests.get(url)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    soup = bs(dump.content,'html.parser')\\n\",\n",
    "        \"\\n\",\n",
    "        \"    tbodies = soup.find('div',{'id':'tabP-1'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"    li = tbodies.find_all('div',{'class':'outerRecSec'})\\n\",\n",
    "        \"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    for i in range(len(li)):\\n\",\n",
    "        \"      if i == 0 :\\n\",\n",
    "        \"        print(f'Name, Designation, Company, Skills Needed, Location')\\n\",\n",
    "        \"\\n\",\n",
    "        \"      name = li[i].find('span',{'class':'fl ellipsis'}).text\\n\",\n",
    "        \"      des = li[i].find('span',{'class':'ellipsis clr'}).text\\n\",\n",
    "        \"      com = li[i].find_all('a',{'class':'ellipsis'})[1].attrs['title']\\n\",\n",
    "        \"      skills = li[i].find('div',{'class':'hireSec highlightable'}).text\\n\",\n",
    "        \"      \\n\",\n",
    "        \"      lov = li[i].find('small',{'class':'ellipsis'}).text\\n\",\n",
    "        \"          \\n\",\n",
    "        \"      \\n\",\n",
    "        \"\\n\",\n",
    "        \"      print(f'{name},{des},{com},{skills}.{lov}')\\n\",\n",
    "        \"      \\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"if __name__=='__main__':\\n\",\n",
    "        \"  maion(url)\"\n",
    "      ],\n",
    "      \"execution_count\": 155,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"Name, Designation, Company, Skills Needed, Location\\n\",\n",
    "            \"Aakash Harit,HR Manager,Data Science Network,    Classic ASP Developer,   Internet Marketing Professional,   Data Science SME,   Content Writers,   SEO Professional,   Revenue Professional    .Delhi\\n\",\n",
    "            \"MARSIAN Technologies LLP,Company HR,MARSIAN Technologies LLP,    Data Science,   Artificial Intelligence,   Machine Learning,   Business Analytics    .Pune\\n\",\n",
    "            \"subhas patel,Founder CEO,LibraryXProject,    Hadoop,   Spark,   Digital Strategy,   Data Architecture,   Command Center,   Cdp,   Dmp,   Kafka,   Data Science,   Data Analysis,   Big Data Analytics,   Real Time Analysis,   SQL    .UK - (london)\\n\",\n",
    "            \"Institute for Financial Management and Resear,Programme Manager,IFMR,    Data Science    .Chennai\\n\",\n",
    "            \"Asif Lucknowi,Director,Weupskill- Live Wire India,    Technical Training,   Software Development,   Presentation Skills,   B.tech,   M.tech,   B.e.,   mca,   msc,   Computer Science,   freshers,   jobs in indore,   Data Science,   itil    .Indore\\n\",\n",
    "            \"Priyanka Akiri,HR Manager,Infinitive Software Solutions Pvt.Ltd.,    Oracle Dba,   Data Science,   Data Warehousing,   ETL,   Jupyter,   Numpy,   Data Transformation,   Snowflake,   Teradata,   Python,   Data Manipulation,   Relational Databases    .Hyderabad\\n\",\n",
    "            \"Mubarak,Company HR,MoneyTap,    Business Intelligence,   Data Warehousing,   Data Science,   Business Analytics,   Customer Support,   Business Reporting,   Bi    .Bengaluru / Bangalore\\n\",\n",
    "            \"Ruchi Dhote,Senior Executive Talent Acquisition,Bristlecone India Ltd,    Qlikview,   Qlik Sense,   Microsoft Azure,   Power Bi,   Data Science,   Machine Learning    .Pune\\n\",\n",
    "            \"Kapil Devang,HR Manager,BISP Solutions,    Big Data,   Hadoop,   Data Analytics,   Data Science    .Bhopal\\n\",\n",
    "            \"Riya Rajesh,Manager Talent Acquisition,Novelworx Digital Solutions,    Data Science    .Cochin\\n\",\n",
    "            \"Faizan Kareem,HR MANAGER,FirstTech Consaltants Pvt.Ltd,    Data Analytics,   Data Science,   Machine Learning,   Deep Learning,   Nlp,   Data Mining,   Python,   R,   Database Administration,   Text Mining    .Hyderabad / Secunderabad\\n\",\n",
    "            \"Sandhya Khandagale,HR Recruiter,Compumatrice Multimedia Pvt Ltd,    Big Data,   Data Science,   Artificial Intelligence,   Hadoop,   Ui Development,   Php,   Freelancing,   .Net,   Software Testing,   Sap,   Leadership Hiring    .Pune\\n\",\n",
    "            \"Azahar Shaikh,Company Recruiter,NEAL ANALYTICS SERVICES PVT LTD,    Data Science,   Artificial Intelligence,   Machine Learning,   Data Analytics    .Pune\\n\",\n",
    "            \"kumar,Proprietor,trainin,    Data Science,   Hadoop,   Rpas,   Devops,   Python,   Aws,   Teaching,   Big Data    .Bengaluru / Bangalore\\n\",\n",
    "            \"Rajat Kumar,Founder CEO,R.S Consultancy &amp; Services,    Web Technologies,   Project Management,   Software Architecture,   Data Science,   Object Oriented Programming,   Computer Science,   Electrical Engineering,   Architecture    .Delhi\\n\",\n",
    "            \"Dhruv Dev Dubey,Company Recruitment Head,Confidential,    Server Administartion,   Verilog,   Vhdl,   Digital Marketing,   Market Research,   Property Research,   Legal,   It And Non It Recruitment,   Logistics,   Supply Chain,   Bfsi    .Bengaluru / Bangalore\\n\",\n",
    "            \"Radha Manivasagam,HR Executive,Techcovery,    Python,   Artificial Intelligence,   Machine Learning,   Data Science    .Bengaluru / Bangalore\\n\",\n",
    "            \"Amit Sharma,Consultant,ASCO consulting,    Machine Learning,   Artificial Intelligence,   Data Science,   Software Engineering,   Software Development,   Graduate Engineer Trainee,   Fresher,   Data Analytics,   Java    .New Delhi\\n\",\n",
    "            \"Shashikant Chaudhary,HR Recruiter/HR Excutive,3D India Staffing Research &amp; Consulting Co. India,    Relationship Management,   Retail Sales,   Private Banking,   Mutual Funds,   NISM,   Equity,   Finance,   Financial Products,   Financial Services,   Verbal,   Written    .Aligarh\\n\",\n",
    "            \"Rutuja Pawar,Technical Recruiter,Demand Matrix,    Data Science,   Big Data Analytics,   Digital Marketing,   Content Writing,   Ui Development,   Database Development,   Qa Automation,   Python,   Project Management    .Pune\\n\",\n",
    "            \"Ankit Sinha,Head Analytics,Suntech Global,    B.Tech,   Tableau,   Statistics,   R,   Analytics,   Time Series,   Data Science,   Business Solutions,   SQL,   Technical Skills,   SSAS,   SQL Server,   Analysis Services,   Qlikview    .Mumbai\\n\",\n",
    "            \"Rashi Kacker,Sr Product Manager,Impel Labs Pvt. Ltd.,    Data Science,   Node.js,   Angularjs    .Bengaluru / Bangalore\\n\",\n",
    "            \"Balaji Kolli,Co Founder,Saras Solutions India Pvt Ltd,    Data Analysis,   Learning,   Data Science,   Computer Science,   Communication Skills    .Hyderabad / Secunderabad\\n\",\n",
    "            \"ROHIT Kumar,Architect,LNT Private Limited,    Software Development,   Core Java,   Unit Testing,   Customer Experience,   Problem Solving,   Communication Skills,   Mysql,   Data Science,   Sales Management,   Analytics    .Mumbai\\n\",\n",
    "            \"Shailja Mishra,HR Manager,Certybox Pvt.Ltd.,    consulting,   Education Counseling,   Educational Sales,   Institutional Sales,   pmp,   Data Science,   Business Development,   Revenue Generation,   Sales Achievement,   new    .Noida\\n\"\n",
    "          ],\n",
    "          \"name\": \"stdout\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team Indias international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://www.bcci.tv/.exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html')\n",
    "\n",
    "def heading():\n",
    "  head = soup.find_all('h2')\n",
    "  print(head[1].text)\n",
    "\n",
    "def contentlist():\n",
    "  #find the section where data lies\n",
    "  col = soup.find('table',{'class':'table table-striped'})\n",
    "  insidecol = col.find_all('tr')\n",
    "\n",
    "  for i in range(len(insidecol)):\n",
    "  \n",
    "    print(insidecol[i].text.replace(' ','  -->  ',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "  if dump.status_code == 200:\n",
    "    heading()\n",
    "    print('\\n')\n",
    "    contentlist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://github.com//.exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html')\n",
    "\n",
    "def heading():\n",
    "  head = soup.find_all('h2')\n",
    "  print(head[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentlist():\n",
    "  #find the section where data lies\n",
    "  col = soup.find('table',{'class':'table table-striped'})\n",
    "  insidecol = col.find_all('tr')\n",
    "\n",
    "  for i in range(len(insidecol)):\n",
    "  \n",
    "    print(insidecol[i].text.replace(' ','  -->  ',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-3e3c56dd1da4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-3e3c56dd1da4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def.head()\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://www.naukri.com/exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html')\n",
    "\n",
    "def heading():\n",
    "  head = soup.find_all('h2')\n",
    "  print(head[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-87c425a717a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.naukri.com/exception-handling-selenium.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "driver.get('https://www.naukri.com/exception-handling-selenium.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in range(5):\n",
    "    driver.find_element_by_tag_name('body').send_keys)keys.END\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in range(5):\n",
    "    driver.find_element_by_tag_name('body').send_keys)keys.END\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"execution_count\": 45,\n",
    "\"metadata\": {},\n",
    "\"output_type\": \n",
    "\"execute_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-3939b4b36142>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-3939b4b36142>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for in range(5):\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for in range(5):\n",
    "    driver.find_element_by_tag_name('body').send_keys)keys.END\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ /.exception-handling-selenium.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html')\n",
    "\n",
    "def heading():\n",
    "  head = soup.find_all('h2')\n",
    "  print(head[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contentlist():\n",
    "  #find the section where data lies\n",
    "  col = soup.find('table',{'class':'table table-striped'})\n",
    "  insidecol = col.find_all('tr')\n",
    "\n",
    "  for i in range(len(insidecol)):\n",
    "  \n",
    "    print(insidecol[i].text.replace(' ','  -->  ',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = requests.get(url)\n",
    "soup = bs(dump.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-e379341a7fb3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-e379341a7fb3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    tbodies = soup.find(lambda tag: tag.name=='table' and tag.has_attr('id') and tag['id']==\"table_id\")\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{\n",
    "tbodies = soup.find(lambda tag: tag.name=='table' and tag.has_attr('id') and tag['id']==\"table_id\")\n",
    "\n",
    "rows = tbodies.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "for i in range(37):\n",
    "  try:\n",
    "    val = rows[i].text.split('\\n')\n",
    "    if i == 0 :\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20Uttarakhand', '-', '245,895', '1.30%', '37.351', '-', '193,273', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val)\n",
    "val[0]\n",
    "len(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
